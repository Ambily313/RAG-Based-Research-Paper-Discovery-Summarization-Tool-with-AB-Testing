{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f71dfe8b",
   "metadata": {},
   "source": [
    "# Notebook 04: RAG System Prototype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba70674d",
   "metadata": {},
   "source": [
    "### Build end-to-end retrieval-augmented generation system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91632999",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Coding\\Repo\\RAG-Based-Research-Paper-Discovery-Summarization-Tool-with-AB-Testing\\rag_en\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85974847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RAG SYSTEM PROTOTYPE\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "HF_API_KEY = os.getenv('HUGGINGFACE_API_KEY')\n",
    "\n",
    "if not HF_API_KEY:\n",
    "    print(\"‚ö†Ô∏è  Warning: HUGGINGFACE_API_KEY not found in .env file\")\n",
    "    print(\"Please create a .env file with your API key\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"RAG SYSTEM PROTOTYPE\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94c24696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Loading data and index...\n",
      "‚úì Loaded 2130 papers\n",
      "‚úì Loaded embedding model\n",
      "‚úì Loaded FAISS index (2130 vectors)\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 1. LOAD DATA & INDEX\n",
    "# ================================\n",
    "\n",
    "print(\"\\nüìÇ Loading data and index...\")\n",
    "\n",
    "# Load cleaned papers\n",
    "df = pd.read_csv('../data/arxiv_papers_clean.csv')\n",
    "print(f\"‚úì Loaded {len(df)} papers\")\n",
    "\n",
    "# Load embedding model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "print(\"‚úì Loaded embedding model\")\n",
    "\n",
    "# Load FAISS index\n",
    "index = faiss.read_index('../data/faiss_index.bin')\n",
    "print(f\"‚úì Loaded FAISS index ({index.ntotal} vectors)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa88e07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ================================\n",
    "# 2. RETRIEVAL FUNCTION\n",
    "# ================================\n",
    "\n",
    "def retrieve_relevant_papers(query, top_k=5):\n",
    "    \"\"\"\n",
    "    Retrieve papers most relevant to the query\n",
    "    \n",
    "    Args:\n",
    "        query: User's search query\n",
    "        top_k: Number of papers to retrieve\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with retrieved papers and scores\n",
    "    \"\"\"\n",
    "    start_time = time.time() # START TIMING\n",
    "\n",
    "    # Encode query\n",
    "    query_embedding = model.encode([query], convert_to_numpy=True)\n",
    "    query_normalized = query_embedding / np.linalg.norm(query_embedding)\n",
    "    \n",
    "    # Search in FAISS\n",
    "    distances, indices = index.search(query_normalized.astype('float32'), top_k)\n",
    "    \n",
    "    # Get papers\n",
    "    retrieved_papers = df.iloc[indices[0]].copy()\n",
    "    retrieved_papers['relevance_score'] = distances[0]\n",
    "    \n",
    "    end_time = time.time() # END TIMING\n",
    "    search_latency = end_time - start_time\n",
    "\n",
    "    return retrieved_papers,search_latency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b82dacf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 3. SUMMARIZATION FUNCTION\n",
    "# ================================\n",
    "\n",
    "def summarize_with_llm(text, model_name=\"facebook/bart-large-cnn\", max_length=130):\n",
    "    \"\"\"\n",
    "    Summarize text using Hugging Face Inference API\n",
    "    ...\n",
    "    Returns:\n",
    "        Generated summary and the generation latency (in seconds)\n",
    "    \"\"\"\n",
    "    API_URL = f\"https://api-inference.huggingface.co/models/{model_name}\"\n",
    "    headers = {\"Authorization\": f\"Bearer {HF_API_KEY}\"}\n",
    "    \n",
    "    # Truncate if too long (API limits)\n",
    "    if len(text.split()) > 500:\n",
    "        text = ' '.join(text.split()[:500])\n",
    "    \n",
    "    payload = {\n",
    "        \"inputs\": text,\n",
    "        \"parameters\": {\n",
    "            \"max_length\": max_length,\n",
    "            \"min_length\": 30,\n",
    "            \"do_sample\": False\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    start_time = time.time() # START TIMING\n",
    "    \n",
    "    # Inner function to handle API call and retry\n",
    "    def api_call(url, headers, json_payload):\n",
    "        try:\n",
    "            response = requests.post(url, headers=headers, json=json_payload, timeout=30)\n",
    "            if response.status_code == 200:\n",
    "                result = response.json()\n",
    "                if isinstance(result, list) and len(result) > 0:\n",
    "                    return result[0].get('summary_text', ''), response.status_code\n",
    "            return f\"Error: Could not generate summary (Status {response.status_code})\", response.status_code\n",
    "        except Exception as e:\n",
    "            return f\"Error: {str(e)}\", -1 # Use -1 for generic exception\n",
    "\n",
    "    summary, status_code = api_call(API_URL, headers, payload)\n",
    "    \n",
    "    # If model is loading, wait and retry\n",
    "    if status_code == 503:\n",
    "        print(\"  Model loading... waiting 20 seconds...\")\n",
    "        time.sleep(20)\n",
    "        summary, status_code = api_call(API_URL, headers, payload)\n",
    "\n",
    "    end_time = time.time() # END TIMING\n",
    "    latency = end_time - start_time\n",
    "\n",
    "    return summary, latency # RETURN LATENCY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b450ef56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 4. RAG PIPELINE\n",
    "# ================================\n",
    "\n",
    "def rag_pipeline(query, top_k=3, summarize=True):\n",
    "    \"\"\"\n",
    "    Full RAG pipeline: Retrieve + Generate\n",
    "    \n",
    "    Args:\n",
    "        query: User's question\n",
    "        top_k: Number of papers to retrieve\n",
    "        summarize: Whether to generate summaries\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with retrieved papers and summaries\n",
    "    \"\"\"\n",
    "    print(f\"\\nüîç Query: '{query}'\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Step 1: Retrieve relevant papers\n",
    "    print(f\"\\nüìö Retrieving top {top_k} relevant papers...\")\n",
    "    papers, search_latency = retrieve_relevant_papers(query, top_k) # CAPTURE LATENCY\n",
    "    \n",
    "    print(f\"‚úì Retrieved {len(papers)} papers (Time: {search_latency:.3f}s)\")\n",
    "    \n",
    "    # Step 2: Display papers\n",
    "    results = []\n",
    "    total_summary_latency = 0 # NEW VARIABLE\n",
    "    for idx, (i, paper) in enumerate(papers.iterrows(), 1):\n",
    "        print(f\"\\n{idx}. {paper['title']}\")\n",
    "        print(f\"   Score: {paper['relevance_score']:.4f}\")\n",
    "        print(f\"   Authors: {paper['authors'][:60]}...\")\n",
    "        print(f\"   Categories: {paper['categories']}\")\n",
    "        \n",
    "        result = {\n",
    "            'rank': idx,\n",
    "            'title': paper['title'],\n",
    "            'abstract': paper['abstract_clean'],\n",
    "            'authors': paper['authors'],\n",
    "            'score': paper['relevance_score'],\n",
    "            'pdf_url': paper['pdf_url']\n",
    "        }\n",
    "        \n",
    "        # Step 3: Generate summary if requested\n",
    "        if summarize and HF_API_KEY:\n",
    "            \n",
    "            summary, summary_latency = summarize_with_llm(paper['abstract_clean']) # CAPTURE LATENCY\n",
    "            total_summary_latency += summary_latency # ACCUMULATE LATENCY\n",
    "\n",
    "            print(f\"  Summary: {summary} (Time: {summary_latency:.3f}s)\")\n",
    "            result['summary'] = summary\n",
    "            \n",
    "        \n",
    "        results.append(result)\n",
    "        \n",
    "        if idx < len(papers):  # Avoid rate limiting\n",
    "            time.sleep(1)\n",
    "    \n",
    "    return {\n",
    "        'results': results,\n",
    "        'search_latency': search_latency,\n",
    "        'avg_summary_latency': total_summary_latency / len(papers) if len(papers) > 0 and summarize else 0\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7af4d627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TESTING RAG SYSTEM\n",
      "============================================================\n",
      "\n",
      "üîç Query: 'attention mechanisms in transformers'\n",
      "------------------------------------------------------------\n",
      "\n",
      "üìö Retrieving top 3 relevant papers...\n",
      "‚úì Retrieved 3 papers (Time: 0.046s)\n",
      "\n",
      "1. Vision Transformers: State of the Art and Research Challenges\n",
      "   Score: 0.5049\n",
      "   Authors: Bo-Kai Ruan, Hong-Han Shuai, Wen-Huang Cheng...\n",
      "   Categories: cs.CV\n",
      "  Summary: Transformers have achieved great success in natural language processing. This paper presents a comprehensive overview of the literature on different architecture designs and training tricks. Our goal is to provide a systematic review with the open research opportunities. (Time: 1.846s)\n",
      "\n",
      "2. Tensor-to-Image: Image-to-Image Translation with Vision Transformers\n",
      "   Score: 0.4946\n",
      "   Authors: Yiƒüit G√ºnd√º√ß...\n",
      "   Categories: cs.CV, cs.AI, cs.LG\n",
      "  Summary: Vision transformers paper also proved that they can be used for computer vision tasks. With the help of self-attention, our model was able to generalize and apply to different problems without a single modification. (Time: 1.787s)\n",
      "\n",
      "3. Perspectives and Prospects on Transformer Architecture for Cross-Modal Tasks with Language and Vision\n",
      "   Score: 0.4841\n",
      "   Authors: Andrew Shin, Masato Ishii, Takuya Narihira...\n",
      "   Categories: cs.CV, cs.CL\n",
      "  Summary: Transformer architectures have brought about fundamental changes to computational linguistic field. Success implies drastic changes in cross-modal tasks with language and vision. In this paper, we review some of the most critical milestones in the field. (Time: 2.096s)\n",
      "\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "\n",
      "üîç Query: 'graph neural networks applications'\n",
      "------------------------------------------------------------\n",
      "\n",
      "üìö Retrieving top 3 relevant papers...\n",
      "‚úì Retrieved 3 papers (Time: 0.016s)\n",
      "\n",
      "1. Theory of Graph Neural Networks: Representation and Learning\n",
      "   Score: 0.6616\n",
      "   Authors: Stefanie Jegelka...\n",
      "   Categories: cs.LG, stat.ML\n",
      "  Summary: Graph Neural Networks (GNNs) have become a popular learning model for prediction tasks on nodes, graphs and configurations of points. This article summarizes a selection of the emerging theoretical results on approximation and learning properties of widely used GNNs. (Time: 1.929s)\n",
      "\n",
      "2. Deep Learning and Geometric Deep Learning: an introduction for mathematicians and physicists\n",
      "   Score: 0.6293\n",
      "   Authors: R. Fioresi, F. Zanchetta...\n",
      "   Categories: cs.LG, math-ph, math.MP\n",
      "  Summary: In this expository paper we want to give a brief introduction to the inner functioning of the new and successfull algorithms of Deep Learning and Geometric Deep Learning. We go over the key ingredients for these algorithms: the score and loss function and we explain the main steps for the training of a model. (Time: 2.994s)\n",
      "\n",
      "3. Automated Graph Machine Learning: Approaches, Libraries, Benchmarks and Directions\n",
      "   Score: 0.5737\n",
      "   Authors: Xin Wang, Ziwei Zhang, Haoyang Li, Wenwu Zhu...\n",
      "   Categories: cs.LG, cs.AI\n",
      "  Summary: Graph machine learning has been extensively studied in both academic and industry. As the literature on graph learning booms with a vast number of emerging methods and techniques, it becomes increasingly difficult to manually design the optimal machine learning algorithm for different graph-related tasks. This paper is the first systematic and comprehensive discussion of approaches, libraries as well as directions for automated graph machine learning. (Time: 3.465s)\n",
      "\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "\n",
      "üîç Query: 'few-shot learning methods'\n",
      "------------------------------------------------------------\n",
      "\n",
      "üìö Retrieving top 3 relevant papers...\n",
      "‚úì Retrieved 3 papers (Time: 0.028s)\n",
      "\n",
      "1. An Overview of Deep Learning Architectures in Few-Shot Learning Domain\n",
      "   Score: 0.6662\n",
      "   Authors: Shruti Jadon, Aryan Jadon...\n",
      "   Categories: cs.CV, cs.LG\n",
      "  Summary: Few-Shot Learning (also known as one-shot learning) is a sub-field of machine learning that aims to create models that can learn the desired objective with less data, similar to how humans learn. We have discussed the recent achievements, challenges, and possibilities of improvement of few- shot learning based deep learning architectures. (Time: 2.988s)\n",
      "\n",
      "2. How to fine-tune deep neural networks in few-shot learning?\n",
      "   Score: 0.5979\n",
      "   Authors: Peng Peng, Jiugen Wang...\n",
      "   Categories: cs.LG, cs.CV\n",
      "  Summary: Deep learning has been widely used in data-intensive applications. However, training a deep neural network often requires a large data set. Fine-tuning of a deep model is simple and effective few-shot learning method. (Time: 1.409s)\n",
      "\n",
      "3. Deep Meta-Learning: Learning to Learn in the Concept Space\n",
      "   Score: 0.5929\n",
      "   Authors: Fengwei Zhou, Bin Wu, Zhenguo Li...\n",
      "   Categories: cs.LG\n",
      "  Summary: Few-shot learning remains challenging for meta-learning that learns a learning algorithm ( meta-learner) from many related tasks. We argue that this is due to the lack of a good representation for Meta-learning. We propose deep meta- Learning to integrate the representation power of deep learning into meta- learning. (Time: 1.846s)\n",
      "\n",
      "============================================================\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 5. TEST RAG SYSTEM\n",
    "# ================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TESTING RAG SYSTEM\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Test queries\n",
    "test_queries = [\n",
    "    \"attention mechanisms in transformers\",\n",
    "    \"graph neural networks applications\",\n",
    "    \"few-shot learning methods\"\n",
    "]\n",
    "\n",
    "all_results = {}\n",
    "all_search_latencies = [] # NEW LIST\n",
    "all_summary_latencies = []\n",
    "\n",
    "for query in test_queries:\n",
    "    metrics = rag_pipeline(query, top_k=3, summarize=True)\n",
    "    all_results[query] = metrics['results']\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "\n",
    "    all_search_latencies.append(metrics['search_latency']) # STORE\n",
    "    if metrics['avg_summary_latency'] > 0:\n",
    "        all_summary_latencies.append(metrics['avg_summary_latency']) # STORE\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be3e2139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RETRIEVAL QUALITY EVALUATION\n",
      "============================================================\n",
      "\n",
      "Manual Relevance Assessment:\n",
      "For each query, review if retrieved papers match the topic\n",
      "\n",
      "\n",
      " Query: 'attention mechanisms in transformers'\n",
      "  1. Vision Transformers: State of the Art and Research Challenges...\n",
      "     Relevance score: 0.5049\n",
      "  2. Tensor-to-Image: Image-to-Image Translation with Vision Transformers...\n",
      "     Relevance score: 0.4946\n",
      "  3. Perspectives and Prospects on Transformer Architecture for Cross-Modal...\n",
      "     Relevance score: 0.4841\n",
      "\n",
      " Query: 'graph neural networks applications'\n",
      "  1. Theory of Graph Neural Networks: Representation and Learning...\n",
      "     Relevance score: 0.6616\n",
      "  2. Deep Learning and Geometric Deep Learning: an introduction for mathema...\n",
      "     Relevance score: 0.6293\n",
      "  3. Automated Graph Machine Learning: Approaches, Libraries, Benchmarks an...\n",
      "     Relevance score: 0.5737\n",
      "\n",
      " Query: 'few-shot learning methods'\n",
      "  1. An Overview of Deep Learning Architectures in Few-Shot Learning Domain...\n",
      "     Relevance score: 0.6662\n",
      "  2. How to fine-tune deep neural networks in few-shot learning?...\n",
      "     Relevance score: 0.5979\n",
      "  3. Deep Meta-Learning: Learning to Learn in the Concept Space...\n",
      "     Relevance score: 0.5929\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ================================\n",
    "# 6. EVALUATE RETRIEVAL QUALITY\n",
    "# ================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RETRIEVAL QUALITY EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Manual evaluation: Check if retrieved papers are relevant\n",
    "print(\"\\nManual Relevance Assessment:\")\n",
    "print(\"For each query, review if retrieved papers match the topic\\n\")\n",
    "\n",
    "for query, results in all_results.items():\n",
    "    print(f\"\\n Query: '{query}'\")\n",
    "    for result in results:\n",
    "        print(f\"  {result['rank']}. {result['title'][:70]}...\")\n",
    "        print(f\"     Relevance score: {result['score']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24e05b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CONTEXT WINDOW EXPERIMENT\n",
      "============================================================\n",
      "\n",
      " Retrieving top-1 papers:\n",
      "  Total context words: 97\n",
      "  Average relevance: 0.6542\n",
      "  Min relevance: 0.6542\n",
      "\n",
      " Retrieving top-3 papers:\n",
      "  Total context words: 420\n",
      "  Average relevance: 0.6202\n",
      "  Min relevance: 0.5872\n",
      "\n",
      " Retrieving top-5 papers:\n",
      "  Total context words: 676\n",
      "  Average relevance: 0.6049\n",
      "  Min relevance: 0.5774\n",
      "\n",
      " Insight: top-3 provides good balance of relevance and context\n"
     ]
    }
   ],
   "source": [
    "# 7. COMPARE CONTEXT WINDOW SIZES\n",
    "# ================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CONTEXT WINDOW EXPERIMENT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "query = \"deep learning for image classification\"\n",
    "\n",
    "for k in [1, 3, 5]:\n",
    "    print(f\"\\n Retrieving top-{k} papers:\")\n",
    "    papers,_ = retrieve_relevant_papers(query, top_k=k)\n",
    "    \n",
    "    context_length = sum(papers['abstract_clean'].str.split().str.len())\n",
    "    print(f\"  Total context words: {context_length}\")\n",
    "    print(f\"  Average relevance: {papers['relevance_score'].mean():.4f}\")\n",
    "    print(f\"  Min relevance: {papers['relevance_score'].min():.4f}\")\n",
    "\n",
    "print(\"\\n Insight: top-3 provides good balance of relevance and context\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41b113b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PROMPT ENGINEERING FOR BETTER SUMMARIES\n",
      "============================================================\n",
      "\n",
      "üìÑ Paper: An Optimal Control View of Adversarial Machine Learning...\n",
      "  Query: machine learning\n",
      "\n",
      "1. Standard summary:\n",
      "   (\"I describe an optimal control view of adversarial machine learning. The control costs are defined by the adversary's goals to do harm and be hard to detect. This view encompasses many types of adversaries, including test-item attacks, training-data poisoning, and adversarial reward shaping.\", 2.2076175212860107)\n",
      "\n",
      "2. Query-focused summary:\n",
      "   (\"An optimal control view of adversarial machine learning. The control costs are defined by the adversary's goals to do harm and be hard to detect. This view encompasses many types of adversaria machine learning, including test-item attacks, training-data poisoning, and adversarial reward shaping.\", 2.236933946609497)\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 8. PROMPT ENGINEERING EXPERIMENTS\n",
    "# ================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PROMPT ENGINEERING FOR BETTER SUMMARIES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Experiment with adding context to summarization\n",
    "def summarize_with_context(abstract, query):\n",
    "    \"\"\"Generate query-focused summary\"\"\"\n",
    "    # Prepend query context\n",
    "    contextualized_text = f\"Research question: {query}\\n\\nAbstract: {abstract}\"\n",
    "    return summarize_with_llm(contextualized_text, max_length=150)\n",
    "\n",
    "test_paper = df.iloc[0]\n",
    "test_query = \"machine learning\"\n",
    "\n",
    "print(f\"\\nüìÑ Paper: {test_paper['title'][:60]}...\")\n",
    "print(f\"  Query: {test_query}\")\n",
    "\n",
    "print(\"\\n1. Standard summary:\")\n",
    "summary1 = summarize_with_llm(test_paper['abstract_clean'])\n",
    "print(f\"   {summary1}\")\n",
    "\n",
    "print(\"\\n2. Query-focused summary:\")\n",
    "summary2 = summarize_with_context(test_paper['abstract_clean'], test_query)\n",
    "print(f\"   {summary2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5dd0bc40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SAVING RAG FUNCTIONS FOR APP\n",
      "============================================================\n",
      "\n",
      "# Core RAG functions (to be used in app/utils.py):\n",
      "# - retrieve_relevant_papers()\n",
      "# - summarize_with_llm()\n",
      "# - rag_pipeline()\n",
      "\n",
      "\n",
      "‚úÖ RAG prototype complete!\n",
      "Functions ready to be integrated into Streamlit app\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 9. SAVE RAG FUNCTIONS\n",
    "# ================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SAVING RAG FUNCTIONS FOR APP\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# These functions will be moved to utils.py for the Streamlit app\n",
    "rag_functions = \"\"\"\n",
    "# Core RAG functions (to be used in app/utils.py):\n",
    "# - retrieve_relevant_papers()\n",
    "# - summarize_with_llm()\n",
    "# - rag_pipeline()\n",
    "\"\"\"\n",
    "\n",
    "print(rag_functions)\n",
    "print(\"\\n‚úÖ RAG prototype complete!\")\n",
    "print(\"Functions ready to be integrated into Streamlit app\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fcb78d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RAG SYSTEM SUMMARY\n",
      "============================================================\n",
      "Embedding Model: all-MiniLM-L6-v2\n",
      "Summarization Model: facebook/bart-large-cnn\n",
      "Retrieval Method: FAISS + Cosine Similarity\n",
      "Optimal Context Window: top-3 papers\n",
      "Avg Search Latency: 29.68ms\n",
      "Avg Summary Generation Time (per paper): 2.26 seconds\n",
      "\n",
      "‚úÖ Ready for A/B testing in notebook 05\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 10. SUMMARY\n",
    "# ================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RAG SYSTEM SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# CALCULATE ACTUAL AVERAGES\n",
    "avg_search_latency = np.mean(all_search_latencies) if all_search_latencies else 0\n",
    "avg_summary_latency = np.mean(all_summary_latencies) if all_summary_latencies else 0\n",
    "\n",
    "summary_stats = {\n",
    "    'Embedding Model': 'all-MiniLM-L6-v2',\n",
    "    'Summarization Model': 'facebook/bart-large-cnn',\n",
    "    'Retrieval Method': 'FAISS + Cosine Similarity',\n",
    "    'Optimal Context Window': 'top-3 papers',\n",
    "    'Avg Search Latency': f'{avg_search_latency*1000:.2f}ms', # Use real value\n",
    "    'Avg Summary Generation Time (per paper)': f'{avg_summary_latency:.2f} seconds' # Use real value\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for key, value in summary_stats.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "print(\"\\n‚úÖ Ready for A/B testing in notebook 05\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8270ad83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0a4cac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab4326b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69eebd9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3922f7dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_en",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
