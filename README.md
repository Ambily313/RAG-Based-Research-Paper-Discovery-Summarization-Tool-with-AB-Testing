
# ğŸ“š RAG-Based Research Paper Discovery & Summarization Tool with A/B Testing

A data science project demonstrating end-to-end ML pipeline development with **Retrieval-Augmented Generation (RAG)**, vector databases, and **A/B testing**.

---

##  Project Overview
This project builds a **semantic search and summarization system** for academic papers, showcasing:

- âœ… End-to-end data pipeline (collection â†’ preprocessing â†’ embeddings â†’ retrieval)  
- âœ… RAG implementation with vector databases  
- âœ… Model evaluation through A/B testing  
- âœ… Interactive demo with Streamlit  

---
##  Key Features

- **Semantic Search** â†’ Find papers by meaning using Sentence-BERT embeddings  
- **FAISS Integration** â†’ Fast similarity search with minimal average latency  
- **AI Summarization** â†’ Generate concise summaries using HuggingFace LLMs  
- **A/B Testing** â†’ Compare **BART** vs **DistilBART** summarization models
  - Uses user preference logs + statistical analysis (Chi-square, t-tests)
  - Results help determine the best summarizer for academic papers
- **Interactive UI** â†’ Streamlit app for live demos and user studies  


##  Tech Stack

| Component        | Technology                                   |
|------------------|-----------------------------------------------|
| **Language**     | Python 3.8+                                  |
| **Embeddings**   | Sentence-Transformers (`all-MiniLM-L6-v2`)   |
| **Vector DB**    | FAISS                                        |
| **LLMs**         | HuggingFace API (BART, DistilBART)                   |
| **Frontend**     | Streamlit                                    |
| **Data Source**  | ArXiv API                                    |
| **Analysis**     | Pandas, NumPy, SciPy, Matplotlib             |

---
##  Getting Started

1. **Clone this repository**
   ```bash
   git clone https://github.com/your-username/RAG-Based-Research-Paper-Discovery-Summarization-Tool-with-AB-Testing.git
   cd RAG-Based-Research-Paper-Discovery-Summarization-Tool-with-AB-Testing
2. **Create a virtual environment & install dependencies**
   ```bash
   pip install -r requirements.txts
3. **Set up API keys**
   ```bash
   Copy .env.example â†’ .env and add your HuggingFace / ArXiv credentials.

3. **Run the Streamlit app**
   ```bash
   streamlit run app/rag_app.py

## ğŸ“ Project Structure

```plaintext

rag-research-papers/
â”‚
â”œâ”€â”€ notebooks/                          # ML workflow notebooks
â”‚   â”œâ”€â”€ 01_data_collection.ipynb        # Scrape ArXiv papers
â”‚   â”œâ”€â”€ 02_eda_preprocessing.ipynb      # Exploratory analysis & cleaning
â”‚   â”œâ”€â”€ 03_embeddings_faiss.ipynb       # Generate embeddings & build FAISS index
â”‚   â”œâ”€â”€ 04_rag_prototype.ipynb          # RAG prototype system
â”‚   â””â”€â”€ 05_ab_testing_analysis.ipynb    # A/B testing & statistical analysis
â”‚
â”œâ”€â”€ app/                                # Application code
â”‚   â”œâ”€â”€ rag_app.py                      # Streamlit app
â”‚   â””â”€â”€ utils.py                        # Helper functions
â”‚
â”œâ”€â”€ data/                               # Data & artifacts
â”‚   â”œâ”€â”€ arxiv_papers.csv                # Raw paper data
â”‚   â”œâ”€â”€ arxiv_papers_clean.csv          # Preprocessed paper data
â”‚   â”œâ”€â”€ embeddings.npy                  # Paper embeddings
â”‚   â”œâ”€â”€ faiss_index.bin                 # FAISS vector index
â”‚   â””â”€â”€ ab_test_logs.csv                # User preference logs
â”‚
â”œâ”€â”€ docs/                               # Documentation
â”‚   â”œâ”€â”€ Technical_Architecture.png      # System architecture diagram   
â”‚   
â”œâ”€â”€ requirements.txt                    # Python dependencies
â”œâ”€â”€ .env                                # API keys template
â”œâ”€â”€ CHANGELOG.md                        # Project changelog
â””â”€â”€ README.md                           # Project documentation
